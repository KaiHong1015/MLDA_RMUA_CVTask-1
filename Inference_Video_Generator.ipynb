{"cells":[{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2021-05-31T08:22:47.238990Z","iopub.status.busy":"2021-05-31T08:22:47.238701Z","iopub.status.idle":"2021-05-31T08:22:48.437148Z","shell.execute_reply":"2021-05-31T08:22:48.436299Z","shell.execute_reply.started":"2021-05-31T08:22:47.238959Z"},"trusted":true},"outputs":[],"source":["import numpy as np\r\n","import os\r\n","import time\r\n","import gc\r\n","import cv2\r\n","import torch\r\n","import torchvision\r\n","import albumentations as A\r\n","import matplotlib\r\n","import matplotlib.pyplot as plt\r\n","\r\n","from ensemble_boxes import *\r\n","from PIL import Image\r\n","from albumentations.pytorch.transforms import ToTensorV2\r\n","from torch.utils.data import Dataset, DataLoader\r\n","from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\r\n","\r\n","%matplotlib inline\r\n","matplotlib.rcParams['figure.figsize'] = (30,30)\r\n","matplotlib.rcParams['font.size'] = 14"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2021-05-31T08:22:48.439184Z","iopub.status.busy":"2021-05-31T08:22:48.438848Z","iopub.status.idle":"2021-05-31T08:22:48.457522Z","shell.execute_reply":"2021-05-31T08:22:48.456715Z","shell.execute_reply.started":"2021-05-31T08:22:48.439147Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Running in cuda\n"]}],"source":["def seed_everything(seed=42):\r\n","    os.environ['PYTHONHASHSEED'] = str(seed)\r\n","    np.random.seed(seed)\r\n","    torch.manual_seed(seed)\r\n","    torch.cuda.manual_seed(seed)\r\n","    torch.backends.cudnn.deterministic = True\r\n","    torch.backends.cudnn.benchmark = True\r\n","    \r\n","seed_everything()\r\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\r\n","print(f'Running in {device}')"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2021-05-31T08:27:53.915942Z","iopub.status.busy":"2021-05-31T08:27:53.915604Z","iopub.status.idle":"2021-05-31T08:27:54.795470Z","shell.execute_reply":"2021-05-31T08:27:54.794664Z","shell.execute_reply.started":"2021-05-31T08:27:53.915911Z"},"trusted":true},"outputs":[],"source":["def get_model(checkpoint_path):\r\n","    model = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=False, pretrained_backbone=False)\r\n","    in_features = model.roi_heads.box_predictor.cls_score.in_features\r\n","    model.roi_heads.box_predictor = FastRCNNPredictor(in_features, 5)\r\n","    \r\n","    checkpoint = torch.load(checkpoint_path)\r\n","    model.load_state_dict(checkpoint)\r\n","    model = model.to(device)\r\n","    model.eval()\r\n","    del checkpoint\r\n","    gc.collect()\r\n","    \r\n","    return model\r\n","\r\n","\r\n","# models = [\r\n","#     get_model('../input/objectdetection/fold0_resnet50_BestModel.pth'), \r\n","#     get_model('../input/objectdetection/fold1_resnet50_BestModel.pth'),\r\n","#     get_model('../input/objectdetection/fold2_resnet50_BestModel.pth'),\r\n","#     get_model('../input/objectdetection/fold3_resnet50_BestModel.pth'), \r\n","#     get_model('../input/objectdetection/fold4_resnet50_BestModel.pth'),\r\n","#     get_model('../input/objectdetection/fold5_resnet50_BestModel.pth'),\r\n","# ]\r\n","\r\n","model = get_model('weight\\\\fold1_resnet50_fpn_BestModel.pth')"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2021-05-31T09:09:03.328088Z","iopub.status.busy":"2021-05-31T09:09:03.327723Z","iopub.status.idle":"2021-05-31T09:09:03.336606Z","shell.execute_reply":"2021-05-31T09:09:03.335658Z","shell.execute_reply.started":"2021-05-31T09:09:03.328056Z"},"trusted":true},"outputs":[],"source":["transform = {\r\n","    'test': A.Compose([A.Resize(height=720, width=1280, p=1.0),\r\n","                      ToTensorV2(p=1.0)], p=1.0)\r\n","}\r\n","\r\n","class CarTestDataset(Dataset):\r\n","    def __init__(self, image_root, depthmaps_path, transform=transform['test']):\r\n","        self.image_root = image_root\r\n","        self.transform = transform\r\n","        self.image_paths = [image_root + '/' + image_root.split('/')[-1].split('_')[-3] + f'_{i}_image.jpg' for i in range(901)]\r\n","        self.depthmaps = np.load(depthmaps_path)\r\n","        self.isleft = True if image_root.split('/')[-1].split('_')[-2]=='left' else False\r\n","        \r\n","    def __getitem__(self, index):\r\n","        image_path = self.image_paths[index]\r\n","        image = Image.open(image_path).convert('RGB')\r\n","        image = np.array(image).astype(np.float32) / 255.0\r\n","        \r\n","        tsfm = self.transform(**{'image':image})\r\n","\r\n","        return tsfm['image'], self.depthmaps[index], self.isleft\r\n","    \r\n","    def __len__(self):\r\n","        return len(self.image_paths)"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2021-05-31T09:21:36.559900Z","iopub.status.busy":"2021-05-31T09:21:36.559524Z","iopub.status.idle":"2021-05-31T09:21:36.565292Z","shell.execute_reply":"2021-05-31T09:21:36.564368Z","shell.execute_reply.started":"2021-05-31T09:21:36.559864Z"},"trusted":true},"outputs":[],"source":["root_dicts = {\r\n","    'video_frames_images/ally_right_images': 'video_frames_images/ally_depth_mm.npy',\r\n","    'video_frames_images/enemy_left_images': 'video_frames_images/enemy_depth_mm.npy',\r\n","    'video_frames_images/ally_left_images': 'video_frames_images/ally_depth_mm.npy',\r\n","    'video_frames_images/enemy_right_images': 'video_frames_images/enemy_depth_mm.npy',\r\n","}\r\n","\r\n","label2color = {\r\n","    1: (30,144,255),\r\n","    2: (0,255,255),\r\n","    3: (255,69,0),\r\n","    4: (240,128,128),\r\n","}\r\n","\r\n","label2str = {\r\n","    1: 'Ally Robot',\r\n","    2: 'Ally Armor',\r\n","    3: 'Enemy Robot',\r\n","    4: 'Enemy Armor',\r\n","}"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2021-05-31T09:21:38.507799Z","iopub.status.busy":"2021-05-31T09:21:38.507483Z","iopub.status.idle":"2021-05-31T09:21:38.527674Z","shell.execute_reply":"2021-05-31T09:21:38.526869Z","shell.execute_reply.started":"2021-05-31T09:21:38.507765Z"},"trusted":true},"outputs":[],"source":["def get_distance(box, label, dm, isleft):\r\n","    '''\r\n","    Calculate the distance of the bounding box predicted from death map\r\n","    \r\n","    Input:\r\n","    box: list or numpy -> a single predicted box\r\n","    label: list or numpy -> a single predicted label\r\n","    isleft: boolean -> Is it the left side camera?\r\n","    \r\n","    Return:\r\n","    d: float -> The calculated distance\r\n","    '''\r\n","    if isleft:\r\n","        c = 50   \r\n","    if not isleft:\r\n","        if label == 1 or label == 3:\r\n","            c = round(175/366 * (box[3]-box[1]))\r\n","        else:\r\n","            c = round(175/45 * (box[3]-box[1]))\r\n","        \r\n","    xmid = round(box[0] + (box[2] - box[0])/2) + c\r\n","    ymid = round(box[1] + (box[3] - box[1])/2)\r\n","    \r\n","    d = dm[ymid-10:ymid, xmid:xmid+17][dm[ymid-10:ymid, xmid:xmid+17]!=0]\r\n","    return 0.0 if not len(d) else d.mean()\r\n","       \r\n","def draw_info(np_image, boxes, labels, isleft):\r\n","    '''\r\n","    Draw predicted bounding box and distance on the image\r\n","    \r\n","    Input:\r\n","    np_image: numpy -> an image in the numpy form\r\n","    boxes: numpy or list -> Predicted bounding boxes of a single image\r\n","    labels: numpy or list -> Predicted labels of a single image\r\n","    isleft: boolean -> Is it the left side camera?\r\n","    \r\n","    Return:\r\n","    np_image: numpy -> An image with info on it\r\n","    '''\r\n","    np_image = np_image.copy()\r\n","    \r\n","    for box, label in zip(boxes, labels):\r\n","        color = label2color[label]\r\n","        name = label2str[label]\r\n","        distance = get_distance(box, label, dm, isleft)\r\n","        text = name + f'({distance/1000:.3f}m)'\r\n","        \r\n","        cv2.rectangle(np_image, (box[0], box[1]), (box[2], box[3]), color, 3)\r\n","        cv2.rectangle(np_image, (box[0], box[1] - 30), (box[0] + round(len(text)/19 * 230), box[1]), color, -1)\r\n","        cv2.putText(np_image, text, (box[0], box[1] - 5), cv2.FONT_HERSHEY_PLAIN, 1.25, (0,0,0), 2)\r\n","    np_image = cv2.cvtColor(np_image, cv2.COLOR_BGR2RGB)\r\n","    return np_image\r\n","    \r\n","def get_valid_prediction(boxes: np.ndarray, scores: np.ndarray, labels: np.ndarray, threshold=0.75):\r\n","    '''\r\n","    Get predictions which satisfied the conditions. We will choose the boxes with confidence>0.75, and set the\r\n","    robot's box as a reference, then calculate the ymin threshold for armor's boxes, as all armor should be at the bottom half of \r\n","    the robot's box\r\n","    \r\n","    Input:\r\n","    boxes: numpy -> Predicted boxes on an single image\r\n","    scores: numpy -> Predicted scores on an single image\r\n","    labels: numpy -> Predicted labels on an single image\r\n","    \r\n","    Return:\r\n","    valid_boxes: list\r\n","    valid_scores: list\r\n","    valid_labels: list\r\n","    '''\r\n","    boxes = boxes[scores > threshold]\r\n","    labels = labels[scores > threshold]\r\n","    scores = scores[scores > threshold]\r\n","    \r\n","    robot_boxes = boxes[np.logical_or(labels==1, labels==3)]\r\n","    robot_labels = labels[np.logical_or(labels==1, labels==3)]\r\n","    robot_scores = scores[np.logical_or(labels==1, labels==3)]\r\n","    \r\n","    armor_boxes = boxes[np.logical_or(labels==2, labels==4)]\r\n","    armor_labels = labels[np.logical_or(labels==2, labels==4)]\r\n","    armor_scores = scores[np.logical_or(labels==2, labels==4)]\r\n","    \r\n","    if len(robot_boxes) > 0:\r\n","        ymin_ref = robot_boxes[:, 1].mean()\r\n","        ymax_ref = robot_boxes[:, 3].mean()\r\n","\r\n","        armor_ymin_threshold = ymin_ref + (ymax_ref - ymin_ref) / 2\r\n","\r\n","        armor_labels = armor_labels[armor_boxes[:, 1] >= armor_ymin_threshold]\r\n","        armor_scores = armor_scores[armor_boxes[:, 1] >= armor_ymin_threshold]\r\n","        armor_boxes = armor_boxes[armor_boxes[:, 1] >= armor_ymin_threshold]\r\n","\r\n","    valid_boxes = []\r\n","    valid_labels = []\r\n","    valid_scores = []\r\n","\r\n","    for box, score, label in zip(robot_boxes, robot_scores, robot_labels):\r\n","        valid_boxes.append(box)\r\n","        valid_scores.append(score)\r\n","        valid_labels.append(label)\r\n","\r\n","    for box, score, label in zip(armor_boxes, armor_scores, armor_labels):\r\n","        valid_boxes.append(box)\r\n","        valid_scores.append(score)\r\n","        valid_labels.append(label)\r\n","    \r\n","    return valid_boxes, valid_scores, valid_labels\r\n","\r\n","@torch.no_grad()\r\n","def make_prediction(image):\r\n","    '''\r\n","    Make prediction on a single image\r\n","    \r\n","    Input:\r\n","    image: tensor with shape (channels, height, width) #without batch_size!!!!\r\n","    \r\n","    Return:\r\n","    prediction: dictionary which contain (boxes, scores, labels)\r\n","    np_image: a numpy image of the input image\r\n","    '''\r\n","    np_image = np.ascontiguousarray(image.permute(1,2,0).mul(255).byte().cpu())\r\n","    prediction = model(image.unsqueeze(0).to(device))\r\n","    return prediction, np_image\r\n","\r\n","def run_wbf(prediction, image_max_size, weights=None, iou_thr=0.55, skip_box_thr=0.75):\r\n","    boxes = [(prediction[0]['boxes'].clip(min=0, max=image_max_size-1)/(image_max_size-1)).tolist()]\r\n","    scores = [prediction[0]['scores'].tolist()]\r\n","    labels = [prediction[0]['labels'].tolist()]\r\n","\r\n","    boxes, scores, labels = weighted_boxes_fusion(boxes, scores, labels, weights=weights, iou_thr=iou_thr, skip_box_thr=skip_box_thr)\r\n","    boxes = (boxes * (image_max_size-1)).clip(min=0, max=image_max_size-1).astype(np.int32)\r\n","    return boxes, scores, labels"]},{"cell_type":"code","execution_count":78,"metadata":{"execution":{"iopub.execute_input":"2021-05-31T09:21:39.488580Z","iopub.status.busy":"2021-05-31T09:21:39.488254Z","iopub.status.idle":"2021-05-31T09:29:16.853944Z","shell.execute_reply":"2021-05-31T09:29:16.852360Z","shell.execute_reply.started":"2021-05-31T09:21:39.488542Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["ally_right_images.avi is done!!\n","\n","enemy_right_images.avi is done!!\n","\n","ally_left_images.avi is done!!\n","\n","enemy_left_images.avi is done!!\n","\n","Average FPS: 7.8801\n"]}],"source":["start = time.time()\r\n","for image_root, dm_path in root_dicts.items():\r\n","    test_ds = CarTestDataset(image_root=image_root, depthmaps_path=dm_path)\r\n","    \r\n","    video_filename = 'result_videos/' + image_root.split('/')[-1] + '.avi'\r\n","    size = (1280, 720)\r\n","\r\n","    out = cv2.VideoWriter(video_filename, cv2.VideoWriter_fourcc(*'DIVX'), 15, size)\r\n","    \r\n","    for i, ds in enumerate(test_ds):\r\n","        image, dm, isleft = ds\r\n","\r\n","        prediction, np_image = make_prediction(image)\r\n","        \r\n","        boxes, scores, labels = run_wbf(prediction=prediction, image_max_size=1280)\r\n","        boxes, scores, labels = get_valid_prediction(boxes, scores, labels)\r\n","        \r\n","        np_image = draw_info(np_image, boxes, labels, isleft)\r\n","\r\n","        out.write(np_image)\r\n","    \r\n","    out.release()\r\n","\r\n","    print(f'{video_filename} is done!!\\n')\r\n","print('Average FPS:', f'{(901 * 4 / (time.time()-start)):.4f}')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3.7.9 64-bit","name":"python379jvsc74a57bd04ac2bbc7d624d29689e0cb66c5c8c7e0d06fefc46b8ac252120ca4495a303042"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.9"},"metadata":{"interpreter":{"hash":"4ac2bbc7d624d29689e0cb66c5c8c7e0d06fefc46b8ac252120ca4495a303042"}},"orig_nbformat":3},"nbformat":4,"nbformat_minor":4}